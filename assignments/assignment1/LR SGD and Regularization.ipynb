{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment1: Logistic Regression, SGD, and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sst_home = '../trees'\n",
    "\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Let's do 2-way positive/negative classification instead of 5-way\n",
    "easy_label_map = {0:0, 1:0, 2:None, 3:1, 4:1}\n",
    "\n",
    "def load_sst_data(path):\n",
    "    data = []\n",
    "    with open(path) as f:\n",
    "        for i, line in enumerate(f): \n",
    "            example = {}\n",
    "            example['label'] = easy_label_map[int(line[1])]\n",
    "            if example['label'] is None:\n",
    "                continue\n",
    "            \n",
    "            # Strip out the parse information and the phrase labels---we don't need those here\n",
    "            text = re.sub(r'\\s*(\\(\\d)|(\\))\\s*', '', line)\n",
    "            example['text'] = text[1:]\n",
    "            data.append(example)\n",
    "\n",
    "    random.seed(1)\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "     \n",
    "training_set = load_sst_data(sst_home + '/train.txt')\n",
    "dev_set = load_sst_data(sst_home + '/dev.txt')\n",
    "test_set = load_sst_data(sst_home + '/test.txt')\n",
    "\n",
    "#print(training_set[0])\n",
    "#print(dev_set)\n",
    "#print(test_set)\n",
    "\n",
    "# Note: Unlike with feature based classifiers, evaluation here should be fast, \n",
    "# and we don't need to trim down the dev and test sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And extract bag-of-words feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "def feature_function(datasets):\n",
    "    '''Annotates datasets with feature vectors.'''\n",
    "    \n",
    "    # Extract vocabulary\n",
    "    def tokenize(string):\n",
    "        return string.split()\n",
    "    \n",
    "    word_counter = collections.Counter()\n",
    "    for example in datasets[0]:\n",
    "        word_counter.update(tokenize(example['text']))\n",
    "    \n",
    "    vocabulary = set([word for word in word_counter])\n",
    "                                \n",
    "    feature_names = set()\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        for example in dataset:\n",
    "            example['features'] = collections.defaultdict(float)\n",
    "            \n",
    "            # Extract features (by name) for one example\n",
    "            word_counter = collections.Counter(tokenize(example['text']))\n",
    "            for x in word_counter.items():\n",
    "                if x[0] in vocabulary:\n",
    "                    example[\"features\"][\"word_count_for_\" + x[0]] = x[1]\n",
    "            \n",
    "            feature_names.update(example['features'].keys())\n",
    "                            \n",
    "    # By now, we know what all the features will be, so we can\n",
    "    # assign indices to them.\n",
    "    feature_indices = dict(zip(feature_names, range(len(feature_names))))\n",
    "    indices_to_features = {v: k for k, v in feature_indices.items()}\n",
    "    dim = len(feature_indices)\n",
    "                \n",
    "    # Now we create actual vectors from those indices.\n",
    "    for dataset in datasets:\n",
    "        for example in dataset:\n",
    "            example['vector'] = np.zeros((dim))\n",
    "            for feature in example['features']:\n",
    "                example['vector'][feature_indices[feature]] = example['features'][feature]\n",
    "    return indices_to_features, dim\n",
    "    \n",
    "indices_to_features, dim = feature_function([training_set, dev_set, test_set])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And define an evalution function. This is a bit different, since it's designed to let us test an entire big batch of examples at once with the classifier, rather than passing them in one by one. (For larger models or larger training sets, this could run out of memory, but it should be fine for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classifier(classifier, eval_set):\n",
    "    correct = 0\n",
    "    hypotheses = classifier(eval_set)\n",
    "    for i, example in enumerate(eval_set):\n",
    "        hypothesis = hypotheses[i]\n",
    "        if hypothesis == example['label']:\n",
    "            correct += 1        \n",
    "    return correct / float(len(eval_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fun part! The below should be a working implementation of logistic regression in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class logistic_regression_classifier:\n",
    "    def __init__(self, dim, lr=1.0, epchs=50, l2b=0.01):\n",
    "        # Define the hyperparameters\n",
    "        self.learning_rate = lr  # Maybe? Let's tune this --> BEST learning rate: 0.9\n",
    "        self.training_epochs = epchs  # How long to train for - chosen to fit within class time\n",
    "        self.display_epoch_freq = 1  # How often to test and print out statistics\n",
    "        self.l2_weight=l2b # l2 regularization weight beta --> Best 0.001\n",
    "        self.dim = dim  # The number of features\n",
    "        self.batch_size = 256  # Somewhat arbitrary - can be tuned, but often tune for speed, not accuracy\n",
    "        \n",
    "        # Define the inputs\n",
    "        self.x = tf.placeholder(tf.float32, [None, dim])\n",
    "        self.y = tf.placeholder(tf.int32, [None])\n",
    "        \n",
    "        # Define (most of) the model\n",
    "        self.W = tf.Variable(tf.zeros([self.dim, 2]))\n",
    "        self.b = tf.Variable(tf.zeros([2]))\n",
    "        self.logits = tf.matmul(self.x, self.W) + self.b\n",
    "\n",
    "        # Define the cost function (here, the exp and sum are built in)\n",
    "        # Original no regularization\n",
    "        ##self.cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits, labels=self.y))\n",
    "        # Loss function with L2 Regularization with beta=0.01\n",
    "        regularizer = tf.nn.l2_loss(self.W)\n",
    "        # my initial solution:\n",
    "        ## self.cost = tf.reduce_mean(self.cost+l2b*regularizer) #0.7694954128440367 - 0.7752293577981652\n",
    "        # second solution: \n",
    "        self.cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits, labels=self.y)\n",
    "                                   +self.l2_weight*regularizer) #0.7706422018348624 - 0.7763761467889908\n",
    "        \n",
    "        #self.cost = self.cost+l2b*regularizer #0.7568807339449541\n",
    "        \n",
    "        # This library call performs the main SGD update equation\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "        # Create an operation to fill zero values in for W and b\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        \n",
    "        # Create a placeholder for the session that will be shared between training and evaluation\n",
    "        self.sess = None\n",
    "        \n",
    "    def train(self, training_data, dev_set):\n",
    "        def get_minibatch(dataset, start_index, end_index):\n",
    "            indices = range(start_index, end_index)\n",
    "            vectors = np.vstack([dataset[i]['vector'] for i in indices])\n",
    "            labels = [dataset[i]['label'] for i in indices]\n",
    "            return vectors, labels\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        self.sess.run(self.init)\n",
    "        print('Training.')\n",
    "        scores={} \n",
    "        scores['train']=[]\n",
    "        scores['dev']=[]\n",
    "        scores['cost']=[]\n",
    "        # Training cycle\n",
    "        for epoch in range(self.training_epochs):\n",
    "            random.shuffle(training_set)\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(len(training_set) / self.batch_size)\n",
    "            \n",
    "            # Loop over all batches in epoch\n",
    "            for i in range(total_batch):\n",
    "                # Assemble a minibatch of the next B examples\n",
    "                minibatch_vectors, minibatch_labels = get_minibatch(training_set, \n",
    "                                                                    self.batch_size * i, \n",
    "                                                                    self.batch_size * (i + 1))\n",
    "\n",
    "                # Run the optimizer to take a gradient step, and also fetch the value of the \n",
    "                # cost function for logging\n",
    "                _, c = self.sess.run([self.optimizer, self.cost], \n",
    "                                     feed_dict={self.x: minibatch_vectors,\n",
    "                                                self.y: minibatch_labels})\n",
    "                                                                    \n",
    "                # Compute average loss\n",
    "                avg_cost += c / (total_batch * self.batch_size)\n",
    "                \n",
    "            \n",
    "            # Display some statistics about the step\n",
    "            if (epoch+1) % self.display_epoch_freq == 0:\n",
    "                scores['cost'].append(avg_cost)\n",
    "                scores['train'].append(evaluate_classifier(self.classify, training_set[0:500]))\n",
    "                scores['dev'].append(evaluate_classifier(self.classify, dev_set[0:500]))\n",
    "                print(\"Epoch:\", (epoch+1), \"Cost:\", avg_cost,\n",
    "                      \"Dev acc:\", evaluate_classifier(self.classify, dev_set[0:500]), \n",
    "                      \"Train acc:\", evaluate_classifier(self.classify, training_set[0:500]))\n",
    "            \n",
    "        return scores\n",
    "    \n",
    "    def classify(self, examples):\n",
    "        # This classifies a list of examples\n",
    "        vectors = np.vstack([example['vector'] for example in examples])\n",
    "        logits = self.sess.run(self.logits, feed_dict={self.x: vectors})\n",
    "        return np.argmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"patch.force_edgecolor\" on line 33 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"lines.dotted_pattern\" on line 20 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.major.top\" on line 253 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.month\" on line 231 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"lines.scale_dashes\" on line 21 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.year\" on line 230 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.major.right\" on line 271 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.second\" on line 235 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.minor.bottom\" on line 256 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.minor.top\" on line 255 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"boxplot.meanprops.markerfacecolor\" on line 368 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"boxplot.meanprops.markeredgecolor\" on line 369 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.microsecond\" on line 236 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"boxplot.meanprops.marker\" on line 367 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.hour\" on line 233 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.bottom\" on line 242 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"lines.dashdot_pattern\" on line 19 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.minor.left\" on line 272 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.minor.right\" on line 273 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.top\" on line 241 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"hatch.color\" on line 37 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.day\" on line 232 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"hist.bins\" on line 40 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.major.bottom\" on line 254 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.minute\" on line 234 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.major.left\" on line 270 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"boxplot.meanprops.markersize\" on line 370 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"axes.autolimit_mode\" on line 220 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"scatter.marker\" on line 345 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"lines.dashed_pattern\" on line 18 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"axes.formatter.offset_threshold\" on line 207 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"axes.titlepad\" on line 184 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.left\" on line 258 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"_internal.classic_mode\" on line 526 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"hatch.linewidth\" on line 38 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.right\" on line 259 in\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "/usr/local/lib/python3.4/dist-packages/matplotlib/__init__.py:1069: UserWarning: Bad val \"auto\" on line #360\n",
      "\t\"boxplot.flierprops.markerfacecolor: auto\n",
      "\"\n",
      "\tin file \"/usr/local/lib/python3.4/dist-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle\"\n",
      "\tKey boxplot.flierprops.markerfacecolor: auto does not look like a color arg\n",
      "  (val, error_details, msg))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(title, data, ylim=None, xlabel=\"epochs\", ylabel=\"Accuracy\"):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid()\n",
    "    \n",
    "        \n",
    "    train_scores=data['train']\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    \n",
    "    train_sizes=len(train_scores)\n",
    "    \n",
    "    test_scores=data['cost']\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    dev_scores=data['dev']\n",
    "    dev_scores_mean = np.mean(dev_scores, axis=1)\n",
    "    dev_scores_std = np.std(dev_scores, axis=1)\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, dev_scores_mean - dev_scores_std,\n",
    "                     dev_scores_mean + dev_scores_std, alpha=0.1, color=\"b\")\n",
    "    \n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, dev_scores_mean, 'o-', color=\"b\",\n",
    "             label=\"Developement score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cost\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.\n",
      "Epoch: 1 Cost: 0.00331546048013 Dev acc: 0.55 Train acc: 0.546\n",
      "Epoch: 2 Cost: 0.00263478529329 Dev acc: 0.514 Train acc: 0.496\n",
      "Epoch: 3 Cost: 0.00249056254203 Dev acc: 0.744 Train acc: 0.726\n",
      "Epoch: 4 Cost: 0.00224212899425 Dev acc: 0.662 Train acc: 0.682\n",
      "Epoch: 5 Cost: 0.00228739895478 Dev acc: 0.696 Train acc: 0.75\n",
      "Epoch: 6 Cost: 0.00219461704708 Dev acc: 0.728 Train acc: 0.758\n",
      "Epoch: 7 Cost: 0.00224260316248 Dev acc: 0.754 Train acc: 0.808\n",
      "Epoch: 8 Cost: 0.00215469083438 Dev acc: 0.7 Train acc: 0.73\n",
      "Epoch: 9 Cost: 0.00199595871554 Dev acc: 0.766 Train acc: 0.83\n",
      "Epoch: 10 Cost: 0.00202861852961 Dev acc: 0.684 Train acc: 0.71\n",
      "Epoch: 11 Cost: 0.00198929677545 Dev acc: 0.76 Train acc: 0.802\n",
      "Epoch: 12 Cost: 0.00194010694718 Dev acc: 0.762 Train acc: 0.816\n",
      "Epoch: 13 Cost: 0.00202407771118 Dev acc: 0.78 Train acc: 0.844\n",
      "Epoch: 14 Cost: 0.00194643082149 Dev acc: 0.776 Train acc: 0.866\n",
      "Epoch: 15 Cost: 0.00191508912637 Dev acc: 0.734 Train acc: 0.816\n",
      "Epoch: 16 Cost: 0.00197387474192 Dev acc: 0.782 Train acc: 0.85\n",
      "Epoch: 17 Cost: 0.00190874460343 Dev acc: 0.79 Train acc: 0.868\n",
      "Epoch: 18 Cost: 0.00191612576169 Dev acc: 0.77 Train acc: 0.818\n",
      "Epoch: 19 Cost: 0.0019632310572 Dev acc: 0.774 Train acc: 0.832\n",
      "Epoch: 20 Cost: 0.00188464748121 Dev acc: 0.782 Train acc: 0.878\n",
      "Epoch: 21 Cost: 0.00189990005715 Dev acc: 0.78 Train acc: 0.882\n",
      "Epoch: 22 Cost: 0.00191968544473 Dev acc: 0.78 Train acc: 0.896\n",
      "Epoch: 23 Cost: 0.00188005825125 Dev acc: 0.79 Train acc: 0.87\n",
      "Epoch: 24 Cost: 0.00189209171933 Dev acc: 0.772 Train acc: 0.856\n",
      "Epoch: 25 Cost: 0.00189889177111 Dev acc: 0.792 Train acc: 0.89\n",
      "Epoch: 26 Cost: 0.00189123486376 Dev acc: 0.744 Train acc: 0.816\n",
      "Epoch: 27 Cost: 0.00198009241528 Dev acc: 0.776 Train acc: 0.856\n",
      "Epoch: 28 Cost: 0.00193000973754 Dev acc: 0.74 Train acc: 0.852\n",
      "Epoch: 29 Cost: 0.00187425380055 Dev acc: 0.79 Train acc: 0.848\n",
      "Epoch: 30 Cost: 0.00187639514829 Dev acc: 0.796 Train acc: 0.904\n",
      "Epoch: 31 Cost: 0.0019238340815 Dev acc: 0.792 Train acc: 0.88\n",
      "Epoch: 32 Cost: 0.00191205149275 Dev acc: 0.766 Train acc: 0.876\n",
      "Epoch: 33 Cost: 0.0018751934188 Dev acc: 0.78 Train acc: 0.88\n",
      "Epoch: 34 Cost: 0.00188064917974 Dev acc: 0.718 Train acc: 0.792\n",
      "Epoch: 35 Cost: 0.00191004860594 Dev acc: 0.79 Train acc: 0.874\n",
      "Epoch: 36 Cost: 0.00187711245639 Dev acc: 0.754 Train acc: 0.836\n",
      "Epoch: 37 Cost: 0.00188331634962 Dev acc: 0.744 Train acc: 0.818\n",
      "Epoch: 38 Cost: 0.00188625339177 Dev acc: 0.77 Train acc: 0.886\n",
      "Epoch: 39 Cost: 0.00188348995073 Dev acc: 0.738 Train acc: 0.816\n",
      "Epoch: 40 Cost: 0.00186990805108 Dev acc: 0.788 Train acc: 0.898\n",
      "Epoch: 41 Cost: 0.0018679453405 Dev acc: 0.782 Train acc: 0.91\n",
      "Epoch: 42 Cost: 0.00186038062977 Dev acc: 0.784 Train acc: 0.904\n",
      "Epoch: 43 Cost: 0.00187755691715 Dev acc: 0.792 Train acc: 0.86\n",
      "Epoch: 44 Cost: 0.00191108373649 Dev acc: 0.782 Train acc: 0.878\n",
      "Epoch: 45 Cost: 0.00189213492235 Dev acc: 0.776 Train acc: 0.91\n",
      "Epoch: 46 Cost: 0.00185610342736 Dev acc: 0.776 Train acc: 0.914\n",
      "Epoch: 47 Cost: 0.00186023678355 Dev acc: 0.784 Train acc: 0.908\n",
      "Epoch: 48 Cost: 0.00187261271532 Dev acc: 0.784 Train acc: 0.892\n",
      "Epoch: 49 Cost: 0.00187707810094 Dev acc: 0.79 Train acc: 0.884\n",
      "Epoch: 50 Cost: 0.00188727391004 Dev acc: 0.784 Train acc: 0.886\n"
     ]
    }
   ],
   "source": [
    "#with tf.device('/cpu:0'):\n",
    "classifier = logistic_regression_classifier(dim, 0.9,50,0.001)\n",
    "scores = classifier.train(training_set, dev_set)\n",
    "#    plot_learning_curve(\"testing plot\",scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7672018348623854"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classifier(classifier.classify, dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments\n",
    "\n",
    "### Our goals\n",
    "  1. **Pick an effective learning rate**:\n",
    "      - You could set up the learning rate value by passing it as argument (e.g. in `__init__ (self, dim, lr=1.0, ...)` )\n",
    "      - Try small and larger values to see the behavior of the model.\n",
    "  \n",
    "  2. **Implement L2 regularization:**\n",
    "      - Hint: Add regularization term to overal cost (`self.cost`)\n",
    "      - Tensorflow already built in method for this. Check the API to find out. \n",
    "      - (Optionaly) Code it without using the built in tool for it\n",
    "\n",
    "  3. **Pick an effective L2 weight:**\n",
    "      - You could set up the learning rate value by passing it as argument (e.g. in `__init__ (self, dim, lw=1.0, ...)` )\n",
    "      - Try small and larger values to see the behavior of the model.\n",
    "  \n",
    "  4. **Look at some learning curves:**\n",
    "      - This code might be helpful: http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
